{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:29:23.603595Z",
     "start_time": "2021-12-03T18:29:20.859592Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "import pyedflib\n",
    "from scipy.signal import find_peaks_cwt, welch\n",
    "from scipy.signal import decimate\n",
    "from datetime import timedelta\n",
    "#from mne.filter import filter_data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:29:23.615590Z",
     "start_time": "2021-12-03T18:29:23.611591Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.matlib import repmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical validation of wearable sensor data and ecological momentary assessment (EMA) data in real-life Parkinson monitoring.\n",
    "\n",
    "This notebook provides the code to perform a proof-of-principle, technical validation, belonging to the database shared on DataVerseNL (https://dataverse.nl/dataset.xhtml?persistentId=doi:10.34894/5HHK8H).\n",
    "\n",
    "To use the data and this notebook the following folder structure should be used:\n",
    "- Create one main folder, and call this path in the next cell.\n",
    "- The main folder should contain a folder 'data', and a folder 'results'.\n",
    "- The folder 'data' should contain one folder per patient. Each folder should be named with the patient code, e.g. '110018', and should contain all sensor data edf-files as provided on DataverseNL.\n",
    "- The data-folder will be used to save working files containing extracted sensor and EMA-data, and features.\n",
    "- The results-folder will be used to save the png-images which are the results of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:29:25.799613Z",
     "start_time": "2021-12-03T18:29:25.791629Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r'D:\\Research Project\\NeurologicalDiseaseMonitoring'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Data Preparation - Loading and Selection\n",
    "Loads in sensor and EMA data from raw files.\n",
    "\n",
    "Selects and extracts both EMA and sensor data based on completed beep questionnaires in EMA data. Saves per patient the EMA data and the corresponding sensor data in separate files 'pt_trials.npy' and 'pt_esm.csv'. These files are required to create Features in section II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:29:30.537062Z",
     "start_time": "2021-12-03T18:29:30.513102Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_file_lists(subject):\n",
    "    '''\n",
    "    Creates a list of files for each sensor (Left/right/chest) located in the indicated patients\n",
    "    sensor file folder.\n",
    "    \n",
    "    '''\n",
    "    subj_folder = os.path.join(path,'data',subject)\n",
    "\n",
    "    # sensor names\n",
    "    left_sensors = ['13797', '13799', '13794', '13806']\n",
    "    right_sensors = ['13805', '13801', '13793', '13795']\n",
    "    chest_sensors = ['13804', '13792', '13803', '13796']\n",
    "\n",
    "    edf_files = [f for f in listdir(subj_folder) if (isfile(join(subj_folder, f))) and (f[0] != '_' and f[-3:] == 'edf')]\n",
    "\n",
    "    left_files = []\n",
    "    right_files = []\n",
    "    chest_files = []\n",
    "\n",
    "    for f in edf_files:\n",
    "        if f[0:5] in left_sensors:\n",
    "            left_files.append(join(subj_folder, f))\n",
    "        elif f[0:5] in right_sensors:\n",
    "            right_files.append(join(subj_folder, f))\n",
    "        elif f[0:5] in chest_sensors:\n",
    "            chest_files.append(join(subj_folder, f))\n",
    "\n",
    "    left_files = sorted(left_files)\n",
    "    right_files = sorted(right_files)\n",
    "    chest_files = sorted(chest_files)\n",
    "\n",
    "    return left_files, right_files, chest_files\n",
    "\n",
    "\n",
    "def extract_raw_trials(left_files, right_files, chest_files, esm_frame,\n",
    "                       esm_window_length=15, feature_window_length=60):\n",
    "    '''\n",
    "    Reads the sensor files and aligns the data with the esm data. Then\n",
    "    data quality is checked.\n",
    "    Returns cleaned and synced trial data and ESM beeps\n",
    "    '''\n",
    "\n",
    "    files = [left_files, right_files, chest_files]\n",
    "\n",
    "    n_beeps = esm_frame.shape[0]\n",
    "    n_sensors = len(files)\n",
    "    trials = [[[]] * n_beeps] * n_sensors\n",
    "    trials = np.zeros((n_sensors,n_beeps,int(esm_window_length * WINDOW_LENGTH * 100),6))\n",
    "\n",
    "    found_trials = np.zeros((n_beeps, n_sensors))\n",
    "    for i, f in enumerate(files):\n",
    "        for file in f:\n",
    "            print(file)\n",
    "\n",
    "            # Read the data from the filepath, raise error if file is not in the correct format\n",
    "            try:\n",
    "                labels, timestamps, data, fs = read_edf_data(file)  # as input instead: leftFiles\n",
    "                if data.shape[1] < fs * feature_window_length:\n",
    "                    raise ValueError('File too short to proceed.')\n",
    "            except Exception:\n",
    "                print('%s is broken' % file)\n",
    "                continue\n",
    "\n",
    "            data = pd.DataFrame(data.T, index=timestamps)\n",
    "            for beep in range(n_beeps):\n",
    "                if found_trials[beep, i] == 1:\n",
    "                    continue\n",
    "\n",
    "                # Get the corresponding time\n",
    "                beep_time = pd.to_datetime(esm_frame['beep_time_start'].iloc[beep])\n",
    "                timediff = np.min(np.abs(data.index - beep_time))\n",
    "                # Find corresponding moment for beep time in the sensor data by\n",
    "                # calculating the difference in sensor and beep timestamps and\n",
    "                # select the index with the smallest difference.\n",
    "                if timediff > timedelta(minutes=esm_window_length):\n",
    "                    # If the time difference is larger than the window length,\n",
    "                    # remove beep\n",
    "                    continue\n",
    "                pos = np.argmin(np.abs(data.index - beep_time))\n",
    "                # For the smallest time difference, find the position in the sensor data\n",
    "                if pos > esm_window_length * WINDOW_LENGTH * fs:\n",
    "                    trials[i,beep,:,:] = data.iloc[pos - (int(esm_window_length * WINDOW_LENGTH * fs)):pos].values\n",
    "                    found_trials[beep, i] = 1\n",
    "    \n",
    "    keep = np.sum(found_trials, axis=1) == n_sensors  # Keep trials if all three sensors contain values\n",
    "    trialData = np.zeros((np.sum(keep), int(esm_window_length * WINDOW_LENGTH * fs), 3 * 6))\n",
    "    counter = 0\n",
    "    for beep in range(n_beeps):\n",
    "        if keep[beep]:\n",
    "            temp = np.concatenate((trials[0,beep,:,:], trials[1,beep,:,:], trials[2,beep,:,:]), axis=1)\n",
    "            trialData[counter, :, :] = temp\n",
    "            counter += 1\n",
    "    foundESM = esm_frame.iloc[keep, :]\n",
    "\n",
    "    return trialData, foundESM\n",
    "\n",
    "\n",
    "def read_edf_data(filename):\n",
    "    '''\n",
    "    Reads and .edf file and returns labels, timestamps, signal buffers and samplefrequency.\n",
    "    '''\n",
    "\n",
    "    # Extract data\n",
    "    f = pyedflib.EdfReader(filename)\n",
    "    fs = f.getSampleFrequencies()[0]\n",
    "    n = f.signals_in_file\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    sig_bufs = np.zeros((n, f.getNSamples()[0]))\n",
    "\n",
    "    for i in np.arange(n):\n",
    "        sig_bufs[i, :] = f.readSignal(i)\n",
    "\n",
    "    # Get starting time\n",
    "    starting_time = filename[-19:-4]\n",
    "    starting_time = pd.to_datetime(starting_time, format='%Y%m%d_%H%M%S', errors='ignore')\n",
    "\n",
    "    sig_bufs = decimate(sig_bufs, DOWNSAMPLING, axis=1)\n",
    "    fs = fs / DOWNSAMPLING\n",
    "    freq = '%d ms' % (1000 / fs)\n",
    "    timestamps = pd.date_range(start=starting_time, periods=sig_bufs.shape[1], freq=freq)\n",
    "\n",
    "    return signal_labels, timestamps, sig_bufs, fs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:35:46.629366Z",
     "start_time": "2021-12-03T18:35:40.694Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_trials_per_day_time(esm_frame, left_files, right_files, chest_files, \n",
    "                                esm_window_length=15, feature_window_length=60):\n",
    "    \n",
    "    '''\n",
    "    Ar trebui sa adaptez metoda lor sau sa implementez de la zero?\n",
    "    Care ar fi pasii pe care sa ii urmez?\n",
    "    Am incercat o adaptare a ce au facut ei, insa nu am dus-o pana la capat - nu imi e foarte clara metoda lor\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    morning= {'start': '6:00', 'stop':'12:00'}\n",
    "    afternoon= {'start': '12:01', 'stop':'18:00'}\n",
    "    evening= {'start': '18:01','stop':'00:00'}\n",
    "    \n",
    "    files = [left_files, right_files, chest_files]\n",
    "    \n",
    "    n_beeps = esm_frame.shape[0]\n",
    "    n_sensors = len(files)\n",
    "    \n",
    "    \n",
    "    # Nu sunt sigura cum foloseste trials\n",
    "    # esm_window_length * WINDOW_LENGTH * 100 <- De ce inmulteste cu 100? \n",
    "    # De ce alege shape-ul asta la array-ul de zero-uri? De ce alege hardcodat acel 6 ca si ultima dimensiune?\n",
    "    trials = np.zeros((n_sensors,n_beeps,int(esm_window_length * WINDOW_LENGTH * 100),6))\n",
    "    found_trials = np.zeros((n_beeps, n_sensors))\n",
    "    \n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        for file in f:\n",
    "            print(file)\n",
    "            try:\n",
    "                labels, timestamps, data, fs = read_edf_data(file)  \n",
    "                if data.shape[1] < fs * feature_window_length:\n",
    "                    raise ValueError('File too short to proceed.')\n",
    "            except Exception:\n",
    "                print('%s is broken' % file)\n",
    "                continue\n",
    "                \n",
    "            data = pd.DataFrame(data.T, index=timestamps)\n",
    "            # DataFrame-uri cu fiecare moment al zilei\n",
    "            morning_data= data.between_time(morning['start'], morning['stop'])\n",
    "            afternoon_data= data.between_time(afternoon['start'], afternoon['stop'])\n",
    "            evening_data= data.between_time(evening['start'], evening['stop'])\n",
    "            \n",
    "            \n",
    "            for beep in range(n_beeps):\n",
    "                if found_trials[beep, i] == 1: # Prin asta se asigura ca secventele nu se suprapun?\n",
    "                    continue\n",
    "                    \n",
    "                beep_time = pd.to_datetime(esm_frame['beep_time_start'].iloc[beep])\n",
    "                timediff = np.min(np.abs(data.index - beep_time))\n",
    "               \n",
    "                if timediff > timedelta(minutes=esm_window_length):\n",
    "                    continue\n",
    "                    \n",
    "                pos = np.argmin(np.abs(data.index - beep_time)) \n",
    "                if pos > esm_window_length * WINDOW_LENGTH * fs: # Care e diferenta dintre esm_window_length si WINDOW_LENGTH?\n",
    "                    # Cum ar trebui sa folosesc acele 3 DataFrame-uri, astfel incat sa am secvente de cate 15 min\n",
    "                    # pentru morning, afternoon, evening? Nu sunt sigura cum ar trebui sa adaptez metoda lor.\n",
    "                    trials[i,beep,:,:] = data.iloc[pos - (int(esm_window_length * WINDOW_LENGTH * fs)):pos].values\n",
    "                    found_trials[beep, i] = 1\n",
    "                    \n",
    "    keep = np.sum(found_trials, axis=1) == n_sensors  # Keep trials if all three sensors contain values\n",
    "    trialData = np.zeros((np.sum(keep), int(esm_window_length * WINDOW_LENGTH * fs), 3 * 6)) # de ce alege asa dimensiunile?\n",
    "     # ce e cu ultima dimensiune -> 3*6?\n",
    "    counter = 0\n",
    "    for beep in range(n_beeps):\n",
    "        if keep[beep]: \n",
    "            temp = np.concatenate((trials[0,beep,:,:], trials[1,beep,:,:], trials[2,beep,:,:]), axis=1)\n",
    "            trialData[counter, :, :] = temp\n",
    "            counter += 1\n",
    "    foundESM = esm_frame.iloc[keep, :]\n",
    "\n",
    "    return trialData, foundESM\n",
    "               \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:35:46.629366Z",
     "start_time": "2021-12-03T18:35:41.058Z"
    }
   },
   "outputs": [],
   "source": [
    "WINDOW_LENGTH = 60\n",
    "\n",
    "esm= pd.read_csv(os.path.join(path,'data','EMA_data.csv'))\n",
    "leftFiles, rightFiles, chestFiles = get_file_lists('110018')\n",
    "extract_trials_per_day_time(esm, leftFiles, rightFiles, chestFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T14:31:11.426613Z",
     "start_time": "2021-12-02T14:31:05.890634Z"
    }
   },
   "outputs": [],
   "source": [
    "DOWNSAMPLING=2\n",
    "signal_labels, timestamps, sig_bufs, fs= read_edf_data(r'D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190109_083149.edf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T14:32:29.802779Z",
     "start_time": "2021-12-02T14:32:29.794778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AccX', 'AccY', 'AccZ', 'GyroX', 'GyroY', 'GyroZ']\n"
     ]
    }
   ],
   "source": [
    "print(signal_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T14:56:50.326045Z",
     "start_time": "2021-12-02T14:56:50.314045Z"
    }
   },
   "outputs": [],
   "source": [
    "timestamps_dataframe = pd.DataFrame(sig_bufs.T, index=timestamps, columns= signal_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T15:23:34.103681Z",
     "start_time": "2021-12-02T15:23:34.063691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccX</th>\n",
       "      <th>AccY</th>\n",
       "      <th>AccZ</th>\n",
       "      <th>GyroX</th>\n",
       "      <th>GyroY</th>\n",
       "      <th>GyroZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-09 08:31:49.000</th>\n",
       "      <td>0.126469</td>\n",
       "      <td>0.680922</td>\n",
       "      <td>0.947261</td>\n",
       "      <td>77.769867</td>\n",
       "      <td>172.811525</td>\n",
       "      <td>-40.602077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09 08:31:49.010</th>\n",
       "      <td>0.099570</td>\n",
       "      <td>0.598664</td>\n",
       "      <td>0.951452</td>\n",
       "      <td>50.728401</td>\n",
       "      <td>126.593605</td>\n",
       "      <td>-34.952784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09 08:31:49.020</th>\n",
       "      <td>0.082826</td>\n",
       "      <td>0.623153</td>\n",
       "      <td>0.888479</td>\n",
       "      <td>22.497329</td>\n",
       "      <td>75.558395</td>\n",
       "      <td>-34.294774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09 08:31:49.030</th>\n",
       "      <td>0.122041</td>\n",
       "      <td>0.565980</td>\n",
       "      <td>0.972972</td>\n",
       "      <td>-1.003207</td>\n",
       "      <td>3.575467</td>\n",
       "      <td>-33.553577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09 08:31:49.040</th>\n",
       "      <td>0.076129</td>\n",
       "      <td>0.550131</td>\n",
       "      <td>1.121156</td>\n",
       "      <td>-29.659717</td>\n",
       "      <td>-53.503752</td>\n",
       "      <td>-7.044780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09 22:40:22.950</th>\n",
       "      <td>-1.049318</td>\n",
       "      <td>-0.144576</td>\n",
       "      <td>0.167657</td>\n",
       "      <td>-15.093979</td>\n",
       "      <td>25.935264</td>\n",
       "      <td>-4.658654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09 22:40:22.960</th>\n",
       "      <td>-1.046836</td>\n",
       "      <td>-0.143432</td>\n",
       "      <td>0.164383</td>\n",
       "      <td>-22.476366</td>\n",
       "      <td>24.846170</td>\n",
       "      <td>-10.138564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09 22:40:22.970</th>\n",
       "      <td>-1.039663</td>\n",
       "      <td>-0.135435</td>\n",
       "      <td>0.148317</td>\n",
       "      <td>-26.333440</td>\n",
       "      <td>23.635702</td>\n",
       "      <td>-16.493698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09 22:40:22.980</th>\n",
       "      <td>-0.998398</td>\n",
       "      <td>-0.124766</td>\n",
       "      <td>0.135832</td>\n",
       "      <td>-25.654926</td>\n",
       "      <td>17.672417</td>\n",
       "      <td>-22.659041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-09 22:40:22.990</th>\n",
       "      <td>-0.969071</td>\n",
       "      <td>-0.115056</td>\n",
       "      <td>0.128495</td>\n",
       "      <td>-22.468627</td>\n",
       "      <td>10.401597</td>\n",
       "      <td>-25.749348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5091400 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AccX      AccY      AccZ      GyroX       GyroY  \\\n",
       "2019-01-09 08:31:49.000  0.126469  0.680922  0.947261  77.769867  172.811525   \n",
       "2019-01-09 08:31:49.010  0.099570  0.598664  0.951452  50.728401  126.593605   \n",
       "2019-01-09 08:31:49.020  0.082826  0.623153  0.888479  22.497329   75.558395   \n",
       "2019-01-09 08:31:49.030  0.122041  0.565980  0.972972  -1.003207    3.575467   \n",
       "2019-01-09 08:31:49.040  0.076129  0.550131  1.121156 -29.659717  -53.503752   \n",
       "...                           ...       ...       ...        ...         ...   \n",
       "2019-01-09 22:40:22.950 -1.049318 -0.144576  0.167657 -15.093979   25.935264   \n",
       "2019-01-09 22:40:22.960 -1.046836 -0.143432  0.164383 -22.476366   24.846170   \n",
       "2019-01-09 22:40:22.970 -1.039663 -0.135435  0.148317 -26.333440   23.635702   \n",
       "2019-01-09 22:40:22.980 -0.998398 -0.124766  0.135832 -25.654926   17.672417   \n",
       "2019-01-09 22:40:22.990 -0.969071 -0.115056  0.128495 -22.468627   10.401597   \n",
       "\n",
       "                             GyroZ  \n",
       "2019-01-09 08:31:49.000 -40.602077  \n",
       "2019-01-09 08:31:49.010 -34.952784  \n",
       "2019-01-09 08:31:49.020 -34.294774  \n",
       "2019-01-09 08:31:49.030 -33.553577  \n",
       "2019-01-09 08:31:49.040  -7.044780  \n",
       "...                            ...  \n",
       "2019-01-09 22:40:22.950  -4.658654  \n",
       "2019-01-09 22:40:22.960 -10.138564  \n",
       "2019-01-09 22:40:22.970 -16.493698  \n",
       "2019-01-09 22:40:22.980 -22.659041  \n",
       "2019-01-09 22:40:22.990 -25.749348  \n",
       "\n",
       "[5091400 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T15:11:31.959615Z",
     "start_time": "2021-12-02T15:11:31.847624Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "esm_frame= pd.read_csv(os.path.join(path,'data','EMA_data.csv'))\n",
    "\n",
    "beep_time = pd.to_datetime(esm_frame['beep_time_start'].iloc[0])\n",
    "timediff = np.abs(timestamps_dataframe.index - beep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T15:11:50.847967Z",
     "start_time": "2021-12-02T15:11:50.831985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('133 days 23:22:38')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(timediff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T15:00:06.698029Z",
     "start_time": "2021-12-02T15:00:06.690035Z"
    }
   },
   "outputs": [],
   "source": [
    "morning= {'start': '6:00', 'stop':'12:00'}\n",
    "afternoon= {'start': '12:01', 'stop':'18:00'}\n",
    "evening= {'start': '18:01','stop':'00:00'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T15:39:04.671287Z",
     "start_time": "2021-12-02T15:39:04.447230Z"
    }
   },
   "outputs": [],
   "source": [
    "morning= timestamps_dataframe.between_time(morning['start'], morning['stop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T15:39:11.751214Z",
     "start_time": "2021-12-02T15:39:11.719226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex([       '2019-01-09 08:31:49', '2019-01-09 08:31:49.010000',\n",
       "               '2019-01-09 08:31:49.020000', '2019-01-09 08:31:49.030000',\n",
       "               '2019-01-09 08:31:49.040000', '2019-01-09 08:31:49.050000',\n",
       "               '2019-01-09 08:31:49.060000', '2019-01-09 08:31:49.070000',\n",
       "               '2019-01-09 08:31:49.080000', '2019-01-09 08:31:49.090000',\n",
       "               ...\n",
       "               '2019-01-09 11:59:59.910000', '2019-01-09 11:59:59.920000',\n",
       "               '2019-01-09 11:59:59.930000', '2019-01-09 11:59:59.940000',\n",
       "               '2019-01-09 11:59:59.950000', '2019-01-09 11:59:59.960000',\n",
       "               '2019-01-09 11:59:59.970000', '2019-01-09 11:59:59.980000',\n",
       "               '2019-01-09 11:59:59.990000',        '2019-01-09 12:00:00'],\n",
       "              dtype='datetime64[ns]', length=1249101, freq='10L')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morning.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T16:49:00.284196Z",
     "start_time": "2021-12-02T16:49:00.172217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "            ...\n",
       "            11, 11, 11, 11, 11, 11, 11, 11, 11, 12],\n",
       "           dtype='int64', length=1249101)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morning.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T14:52:22.506030Z",
     "start_time": "2021-12-02T14:52:22.498028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5091400\n"
     ]
    }
   ],
   "source": [
    "print(sig_bufs.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T14:33:34.923148Z",
     "start_time": "2021-12-02T14:33:34.919147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "print(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-03T18:43:29.002684Z",
     "start_time": "2021-12-03T18:36:00.969535Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190109_083149.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190110_092745.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190111_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190111_061000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190112_084509.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190113_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190113_100711.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190114_072923.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190114_212039.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190114_212039.edf is broken\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190115_090812.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190116_081145.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190117_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190117_074510.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190118_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190118_140829.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190119_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190119_065724.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190120_081758.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190121_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190121_071610.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190122_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13797_20190122_092104.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190109_083149.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190110_092745.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190111_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190111_060959.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190112_084508.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190113_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190113_100710.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190114_072921.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190114_212037.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190114_212037.edf is broken\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190115_090810.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190116_081142.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190117_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190117_074508.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190118_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190118_140826.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190119_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190119_065720.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190120_081754.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190121_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190121_071606.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190122_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190122_092102.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190122_215727.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13805_20190122_215727.edf is broken\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190109_083149.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190109_083149.edf is broken\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190110_092745.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190111_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190111_060959.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190112_084507.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190113_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190113_100709.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190114_072918.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190114_212036.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190114_212036.edf is broken\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190115_090809.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190116_081142.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190117_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190117_074507.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190118_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190118_140825.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190119_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190119_065719.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190120_081753.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190121_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190121_071605.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190122_000000.edf\n",
      "D:\\Research Project\\NeurologicalDiseaseMonitoring\\data\\110018\\13804_20190122_092056.edf\n",
      "447.47096824645996\n",
      "(57, 90000, 18)\n",
      "(57, 46)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # constants\n",
    "    WINDOW_LENGTH = 60\n",
    "    DOWNSAMPLING = 2\n",
    "    FEATURE_WINDOW_LENGTH = 60\n",
    "    ESM_WINDOW_LENGTH = 15\n",
    "\n",
    "    # define patient to use\n",
    "    all_subjs = ['110018']\n",
    "\n",
    "    esm = pd.read_csv(os.path.join(path,'data','EMA_data.csv'))\n",
    "\n",
    "    for subject in all_subjs:\n",
    "        leftFiles, rightFiles, chestFiles = get_file_lists(subject)\n",
    "        t = time.time()\n",
    "        trial_data, selected_esm = extract_raw_trials(leftFiles, rightFiles, chestFiles, esm[esm['ID'] == int(subject)])\n",
    "        print(time.time() - t)\n",
    "        print(trial_data.shape)\n",
    "        print(selected_esm.shape)\n",
    "        np.save(os.path.join(path,'data', subject + '_trials.npy'), trial_data.astype(np.float32))\n",
    "        selected_esm.to_csv(os.path.join(path,'data', subject + '_esm.csv'), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Preparation - Feature Extraction\n",
    "\n",
    "The next section requires the files 'pt_trials.npy' and 'pt_esm.csv' in the data-folder as a result of the previous section.\n",
    "It will produce a csv-file containing features for medication state classification. The csv-file will be stored in the data-folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extractFeatures(data, esm,sr, windowLength=60):\n",
    "\n",
    "    numSamples=data.shape[0]\n",
    "    # Getting number and names of features\n",
    "    tremorNames, _ = tremorFeatures(data[0,:windowLength*sr,:], sr,windowLength=windowLength)\n",
    "    bradyNames, _ = bradykinesiaFeatures(data[0,:windowLength*sr,:], sr,windowLength=windowLength)\n",
    "    cols=[]\n",
    "    for s in ['L','R','C']:\n",
    "        cols.extend([c + s for c in tremorNames])\n",
    "        cols.extend([c + s for c in bradyNames])\n",
    "    cols.extend(esm.keys())\n",
    "    aligned = pd.DataFrame(columns=cols)\n",
    "    accelerometerChannel = [a + b for a in  [0,6,12] for b in range(3)]\n",
    "    for beep in np.arange(data.shape[0]):\n",
    "        t=time.time()\n",
    "        allFeat = []\n",
    "        numWindows = int(data.shape[1]/sr/windowLength)\n",
    "        buff = data[beep,:,:]\n",
    "        buff[:,accelerometerChannel] = (buff[:,accelerometerChannel].T - np.mean(buff[:,accelerometerChannel].T,axis=0)).T\n",
    "        for s,sID in enumerate([range(6),range(6,12),range(12,18)]):\n",
    "            \n",
    "            features=np.zeros((numWindows,len(tremorNames)+len(bradyNames)))\n",
    "            for i in range(0,numWindows):\n",
    "                win = i * windowLength * sr\n",
    "                _, features[i,:len(tremorNames)] = tremorFeatures(buff[win:win+windowLength*sr,sID],sr,windowLength=windowLength)\n",
    "                _, features[i,len(tremorNames):] = bradykinesiaFeatures(buff[win:win+windowLength*sr,sID],sr,windowLength=windowLength)\n",
    "            allFeat.append(features)\n",
    "        allFeat = np.concatenate(allFeat,axis=1)\n",
    "        allFeat = np.concatenate((allFeat, np.matlib.repmat(esm.iloc[beep,:],numWindows,1)),axis=1)\n",
    "        aligned = aligned.append(pd.DataFrame(allFeat,columns = cols),ignore_index=True)\n",
    "    \n",
    "    return aligned \n",
    "\n",
    "\n",
    "\n",
    "def tremorFeatures(windowData,sr,windowLength=60):\n",
    "    tremorChannel={'AccX':0,'AccY':1,'AccZ':2,'GyrX':3,'GyrY':4,'GyrZ':5} \n",
    "    if windowData.shape[0]!=sr*windowLength:\n",
    "        print(windowData.shape,sr*windowLength)\n",
    "    features=[]\n",
    "    featureNames=[]\n",
    "    for ch in tremorChannel.keys():\n",
    "        f, spec = welch(windowData[:,tremorChannel[ch]], fs=sr, nperseg=sr )\n",
    "        selected = np.logical_and(f>3.5,f<7.5)\n",
    "        spec = np.mean(np.log(spec[selected]))\n",
    "        features.append(spec)\n",
    "        featureNames.append('TremorPower' + ch)\n",
    "        \n",
    "        \n",
    "    return featureNames, features\n",
    "\n",
    "\n",
    "\n",
    "def bradykinesiaFeatures(windowData,sr,windowLength=60):\n",
    "    features=[]\n",
    "    featureNames=[]\n",
    "    accelerometerChannel={'accX':0,'accY':1,'accZ':2} \n",
    "    windowData = filter_data(windowData[:,list(accelerometerChannel.values())].T,sr,0,3,method='iir',verbose='WARNING').T\n",
    "    \n",
    "    freq = np.fft.rfftfreq(windowLength*sr, d=1./sr)\n",
    "    \n",
    "    for ch in accelerometerChannel.keys():\n",
    "        f, spec = welch(windowData[:,accelerometerChannel[ch]], fs=sr, nperseg=sr )\n",
    "        selected = np.logical_and(f>0.5,f<3.0)\n",
    "        spec = np.mean(np.log(spec[selected])) \n",
    "        features.append(spec)\n",
    "        featureNames.append('bradyPower' + ch)\n",
    "        \n",
    "        spec = np.abs(np.fft.rfft(windowData[:,accelerometerChannel[ch]]))\n",
    "        domFreq = freq[np.argmax(spec)]\n",
    "        features.append(domFreq)\n",
    "        featureNames.append('DomFreq' + ch)\n",
    "        \n",
    "        domEnergyRatio = np.max(spec) / np.sum(spec)\n",
    "        features.append(domEnergyRatio)\n",
    "        featureNames.append('DomEnergyRatio' + ch)\n",
    "        \n",
    "        rms = np.sqrt(np.mean(windowData[:,accelerometerChannel[ch]]**2))\n",
    "        features.append(rms)\n",
    "        featureNames.append('RMS' + ch)\n",
    "        \n",
    "        ampRange = np.max(windowData[:,accelerometerChannel[ch]]) - np.min(windowData[:,accelerometerChannel[ch]])\n",
    "        features.append(ampRange)\n",
    "        featureNames.append('AmpRange' + ch)\n",
    "    \n",
    "    cCMax=[]\n",
    "    cCLocs=[]\n",
    "    for i, ch1 in enumerate(accelerometerChannel.keys()):\n",
    "        for j,ch2 in enumerate(list(accelerometerChannel.keys())[i+1:]):\n",
    "            crossCorr = np.correlate(windowData[:,accelerometerChannel[ch1]],windowData[:,accelerometerChannel[ch2]],'same')\n",
    "            crossCorr = crossCorr/(np.std(windowData[:,accelerometerChannel[ch1]]) * np.std(windowData[:,accelerometerChannel[ch2]]))\n",
    "            \n",
    "            cCMax.append(np.max(crossCorr))\n",
    "            cCLocs.append(np.argmax(crossCorr))\n",
    "    features.append(np.max(cCMax))\n",
    "    featureNames.append('MaxCC')\n",
    "    features.append(cCLocs[np.argmax(cCMax)])\n",
    "    featureNames.append('MaxCCLoc')\n",
    "        \n",
    "    return featureNames, features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    allPts = ['110018'] \n",
    "    sr=100\n",
    "    winL = 900 # seconds\n",
    "    for pt in allPts:\n",
    "        print(pt)\n",
    "        trialData = np.load(join(path,'data', pt + '_trials.npy')).astype(np.float64)\n",
    "        esm = pd.read_csv(join(path,'data',  pt + '_esm.csv'))\n",
    "        alignedFeatures = extractFeatures(trialData,esm,sr,windowLength=winL)\n",
    "        alignedFeatures.to_csv(join(path,'data',  pt + '_features' +  str(winL)  + '.csv'),index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Classification Analysis\n",
    "\n",
    "Function to perform classification analysis on Medication States.\n",
    "\n",
    "Needs pre-processed features-fil containing sensor and EMA data from previous section.\n",
    "\n",
    "Requires patient-code as input, and definition of the source of sensor data to use, 'chest' or 'wrists' can be chosen to perform the analysis with respectively chest-sensor data or left- and right-wrist sensor data.\n",
    "The function will store the resulting png-file in the results-folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareWristChest(pt):\n",
    "    '''\n",
    "    Input:\n",
    "    pt = pt-code as string, e.g. '110018'\n",
    "    sensor_source = 'wrists' or 'chest', defines which movement sensors to use for prediction.\n",
    "    \n",
    "    Output:\n",
    "    png file in results-folder.\n",
    "    '''\n",
    "    esmTarget = 'sanpar_onoff'\n",
    "    \n",
    "    esmColumns = ['subjno', 'mood_well', 'mood_down', 'mood_fright', 'mood_tense', 'phy_sleepy', 'phy_tired',\n",
    "           'mood_cheerf', 'mood_relax', 'thou_concent', 'pat_hallu', 'loc_where',\n",
    "           'soc_who', 'soc_who02', 'soc_who03', 'act_what', 'act_what02',\n",
    "           'act_what03', 'act_norpob', 'prob_mobility', 'prob_stillness',\n",
    "           'prob_speech', 'prob_walking', 'tremor', 'slowness',\n",
    "           'stiffness', 'tension', 'dyskinesia', 'onoff',\n",
    "           'medic', 'beep_disturb', '_datetime', '_datetime_e', 'dayno_n', 'beepno_n','duration']\n",
    "\n",
    "    drop=[ 'subjno','soc_who', 'soc_who02', 'soc_who03',  'act_what02', 'loc_where',\n",
    "           'soc_who', 'soc_who02', 'soc_who03',  'act_what02',\n",
    "           'act_what03','_datetime', '_datetime_e', 'dayno_n', 'beepno_n','duration','castorID'] # keep 'act_what' in\n",
    "\n",
    "    fig,ax = plt.subplots(1,2, figsize=(12,6))\n",
    "    sns.set_context('paper')\n",
    "    titles = ['Wrist data\\n(intended use)','Chest data\\n(non-intended use)']\n",
    "    ab = ['A','B']\n",
    "    for n,sensor_source in enumerate(['wrists','chest']):\n",
    "        esmFeatures = pd.read_csv(os.path.join(path,'data',pt+'_features900.csv'),index_col=False)\n",
    "        esmFeatures = esmFeatures.drop(drop, axis=1, errors='ignore')\n",
    "        dat = esmFeatures.drop(esmColumns,axis=1,errors='ignore')\n",
    "\n",
    "        if sensor_source == 'chest':\n",
    "            feats = [c for c in dat.keys() if c[-1] == 'C'] # takes only features from chest-sensor\n",
    "        elif sensor_source == 'wrists':\n",
    "            feats = [c for c in dat.keys() if c[-1] == 'R' ]\n",
    "            feats.extend([c for c in dat.keys() if c[-1] == 'L'])# takes features from left and right wrist-sensor\n",
    "        # define x\n",
    "        dat = dat[feats]\n",
    "        x=dat.loc[~np.isnan(esmFeatures[esmTarget]),:].values\n",
    "        # define y\n",
    "        y=esmFeatures[esmTarget][~np.isnan(esmFeatures[esmTarget])].values\n",
    "        y=y==3 # 3 is ON-answer in EMA\n",
    "\n",
    "        # define classifier, cv to use, and number of cross-validation folds\n",
    "        est=LogisticRegression(solver='lbfgs')\n",
    "        folds = 5 \n",
    "        kf = KFold(n_splits=folds)\n",
    "        scores = np.zeros((y.shape[0],2))\n",
    "        aucs=[]\n",
    "        for fold, (train,test) in enumerate(kf.split(x)): \n",
    "            est.fit(x[train,:],y[train]) \n",
    "            if hasattr(est, \"predict_proba\"): \n",
    "                prob_pos = est.predict_proba(x[test,:])#[:, 0]\n",
    "            else:  \n",
    "                prob_pos = est.decision_function(x[test,:])\n",
    "            scores[test,:]=prob_pos\n",
    "            aucs.append(roc_auc_score(y[test]==1, scores[test,0]))\n",
    "        auc = roc_auc_score(y==1, scores[:,0]) \n",
    "        (fpr, tpr, treshs) = roc_curve(y==1, scores[:,0]) \n",
    "    #     print('Participant %s has overall auc %f' %(pt,auc)) \n",
    "\n",
    "        ## Plot figure\n",
    "        ax[n].plot(fpr,tpr,'o-', lw=2.5, markersize=8)\n",
    "        ax[n].plot(np.arange(0,1.1,0.1),np.arange(0,1.1,0.1), lw=1.5)\n",
    "        ax[n].set_xlabel('False Positive Rate', fontsize=18)\n",
    "        ax[n].set_ylabel('True Positive Rate',fontsize=18)\n",
    "        ax[n].set_title(titles[n],fontsize=20)\n",
    "        ax[n].set_xticks([0,0.2,0.4,0.6,0.8,1])\n",
    "        ax[n].set_yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "        ax[n].set_xticklabels([0,0.2,0.4,0.6,0.8,1],fontsize=18)\n",
    "        ax[n].set_yticklabels([0,0.2,0.4,0.6,0.8,1],fontsize=18)\n",
    "        ax[n].annotate(ab[n], xy=(-.05,1.05), xycoords='axes fraction', fontsize=48)\n",
    "        sns.despine()\n",
    "        ax[n].grid()\n",
    "    plt.tight_layout(w_pad=3)\n",
    "    plt.savefig(os.path.join(path,'results','DATA_fig2.png'),dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compareWristChest('110018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictMedState(pt, sensor_source):\n",
    "    '''\n",
    "    Input:\n",
    "    pt = pt-code as string, e.g. '110018'\n",
    "    sensor_source = 'wrists' or 'chest', defines which movement sensors to use for prediction.\n",
    "    \n",
    "    Output:\n",
    "    png file in results-folder.\n",
    "    '''\n",
    "    esmTarget = 'sanpar_onoff'\n",
    "    \n",
    "    esmColumns = ['subjno', 'mood_well', 'mood_down', 'mood_fright', 'mood_tense', 'phy_sleepy', 'phy_tired',\n",
    "           'mood_cheerf', 'mood_relax', 'thou_concent', 'pat_hallu', 'loc_where',\n",
    "           'soc_who', 'soc_who02', 'soc_who03', 'act_what', 'act_what02',\n",
    "           'act_what03', 'act_norpob', 'prob_mobility', 'prob_stillness',\n",
    "           'prob_speech', 'prob_walking', 'tremor', 'slowness',\n",
    "           'stiffness', 'tension', 'dyskinesia', 'onoff',\n",
    "           'medic', 'beep_disturb', '_datetime', '_datetime_e', 'dayno_n', 'beepno_n','duration']\n",
    "\n",
    "    drop=[ 'subjno','soc_who', 'soc_who02', 'soc_who03',  'act_what02', 'loc_where',\n",
    "           'soc_who', 'soc_who02', 'soc_who03',  'act_what02',\n",
    "           'act_what03','_datetime', '_datetime_e', 'dayno_n', 'beepno_n','duration','castorID'] # keep 'act_what' in\n",
    "\n",
    "    esmFeatures = pd.read_csv(os.path.join(path,'data',pt+'_features900.csv'),index_col=False)\n",
    "    esmFeatures = esmFeatures.drop(drop, axis=1, errors='ignore')\n",
    "    dat = esmFeatures.drop(esmColumns,axis=1,errors='ignore')\n",
    "    ## select defined sensor-data\n",
    "    if sensor_source == 'chest':\n",
    "        feats = [c for c in dat.keys() if c[-1] == 'C'] # takes only features from chest-sensor\n",
    "    elif sensor_source == 'wrists':\n",
    "        feats = [c for c in dat.keys() if c[-1] == 'R' ]\n",
    "        feats.extend([c for c in dat.keys() if c[-1] == 'L'])# takes features from left and right wrist-sensor\n",
    "    # define x\n",
    "    dat = dat[feats]\n",
    "    x=dat.loc[~np.isnan(esmFeatures[esmTarget]),:].values\n",
    "    # define y\n",
    "    y=esmFeatures[esmTarget][~np.isnan(esmFeatures[esmTarget])].values\n",
    "    y=y==3 # 3 is ON-answer in EMA\n",
    "\n",
    "    # define classifier, cv to use, and number of cross-validation folds\n",
    "    est=LogisticRegression(solver='lbfgs')\n",
    "    folds = 5 \n",
    "    kf = KFold(n_splits=folds)\n",
    "    scores = np.zeros((y.shape[0],2))\n",
    "    aucs=[]\n",
    "    for fold, (train,test) in enumerate(kf.split(x)): \n",
    "        est.fit(x[train,:],y[train]) \n",
    "        if hasattr(est, \"predict_proba\"): \n",
    "            prob_pos = est.predict_proba(x[test,:])#[:, 0]\n",
    "        else:  \n",
    "            prob_pos = est.decision_function(x[test,:])\n",
    "        scores[test,:]=prob_pos\n",
    "        aucs.append(roc_auc_score(y[test]==1, scores[test,0]))\n",
    "    auc = roc_auc_score(y==1, scores[:,0]) \n",
    "    (fpr, tpr, treshs) = roc_curve(y==1, scores[:,0]) \n",
    "#     print('Participant %s has overall auc %f' %(pt,auc)) \n",
    "\n",
    "    ## Plot figure\n",
    "    sns.set_context('paper')\n",
    "    fig, ax= plt.subplots(figsize=(6,6))\n",
    "\n",
    "    ax.plot(fpr,tpr,'o-', lw=2.5, markersize=8)\n",
    "    ax.plot(np.arange(0,1.1,0.1),np.arange(0,1.1,0.1), lw=1.5)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=18)\n",
    "    ax.set_ylabel('True Positive Rate',fontsize=18)\n",
    "#     ax.set_title('%s: Medication state detection\\n for %s sensor, AUC = %.2f' % (pt,sensor_source,auc),\n",
    "#                 fontsize=20)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(os.path.join(path,'results','%s_%s_roc.png' %(pt,sensor_source)),dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predictMedState(pt='110018', sensor_source='wrists')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
